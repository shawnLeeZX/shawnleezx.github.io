<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta content="Shawn" property="og:site_name">
  <link href="/favicon.png" rel="icon">

  
  <meta content="Research & Development" property="og:title">
  

  
  <meta content="article" property="og:type">
  

  
  <meta content="<h1>Shawn W. M. Li</h1> " property="og:description">
  

  
  <meta content="http://0.0.0.0:4000/research/" property="og:url">
  

  

  <meta property="og:image" content="">

  

  

  <title>Research &amp; Development - Shawn</title>
  <meta name="description" content="<h1>Shawn W. M. Li</h1> ">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
  <!-- <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/css/bootstrap.min.css" integrity="sha384-GJzZqFGwb1QTTN6wy59ffF1BuGJpLSa9DkKMp0DgiMDm4iYMj70gZWKYbI706tWS" crossorigin="anonymous"> -->
  <!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.slim.min.js"></script> -->
  <!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script> -->
  <!-- <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js" integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k" crossorigin="anonymous"></script> -->
  <link rel="stylesheet" href="/css/main.css">

  <!-- Typesetting math using MathJax -->
  <!-- mathjax config similar to math.stackexchange -->
  <script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     jax: ["input/TeX", "output/HTML-CSS"],
     tex2jax: {
       inlineMath: [ ['$', '$'] ],
       displayMath: [ ['$$', '$$']],
       processEscapes: true,
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     },
     messageStyle: "none",
     "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
   });
  </script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-44220731-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>



  <link href="/css/fonts/orbitron.css" rel="stylesheet" type="text/css">
  <link href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
  <link rel="canonical" href="http://0.0.0.0:4000/research/">
  <link rel="alternate" type="application/rss+xml" title="Shawn" href="http://0.0.0.0:4000/feed.xml">
</head>


  <body>
    <section>
  <nav class="navbar navbar-default navbar-expand-lg fixed-top">
    <div class="container">

      <!-- Brand and toggle get grouped for better mobile display -->
      <a class="navbar-brand" href="/">Shawn</a>
      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navBar">
        <i class="fa fa-bars"></i>
        <span class="navbar-toggler-icon"></span>
      </button>

      <div class="collapse navbar-collapse" align="right" id="navBar">
        <ul class="navbar-nav ms-auto">
          <li class="nav-item"><a class="nav-link" href="/about">About</a></li>
          <li class="nav-item"><a class="nav-link" href="/research">Research & Development</a></li>
          <!-- <li class="nav-item"><a class="nav-link" href="/bio">Biography</a></li> -->
          <!-- <li class="nav-item"><a class="nav-link" href="/essays">Essays</a></li> -->
          <!-- <li class="nav-item"><a class="nav-link" href="/community">Community</a></li> -->
        </ul>
      </div><!-- /.navbar-collapse -->

    </div>
  </nav>
</section>


    <section>
      <div class="container">
  <h1 class="page-title" itemprop="name headline">Research & Development</h1>
  
</div>

<div class="container content">
  <p>The following introduces search visions, and problems currently being
worked on.</p>

<h3 id="science-of-intelligence">Science of intelligence</h3>

<p>Previously, I have spent about 10 years investigating first-principle
derivation of Deep Neural Networks (DNNs), crystallizing the ideas in two
papers—<a href="https://zenodo.org/record/5814935">a letter</a> introducing
the main ideas, and a more <a href="https://zenodo.org/record/5814961">technical article</a> (where most
technicalities are put in the ~100 pages appendices).</p>

<p>The basic idea is that deep neural networks (DNNs) are a phenomenological model
of biotic intelligence, and DNNs could be studied similarly to physics through
symmetries, though the symmetries here are not conservative symmetries in
physics, but a symmetry perhaps that might form a different paradigm, and is
referred as <em>adaptive symmetry</em>. The learning process could be formalized as a
symmetries-breaking process where these symmetries are broken to build a model
of the world that could predict the future, such that the uncertainty of
survival and reproduction is decreased; that is, to adapt to the world.</p>

<p>More technically, there exists concentration of measures phenomena for large
DNNs that enable learning of the network to stay within a phase where arbitrary
learning errors could be reduced. That is, biotic or cognitive complexity
arises from adaptive-symmetries breaking.</p>

<h2 id="embodied-intelligence-and-alignment">Embodied intelligence and alignment</h2>

<p>The adaptive-symmetries breaking work sets the first step, or foundation, for
the subsequent efforts. More specifically, the previous works analyze the
simplest yet most fundamental setting, i.e., object classification; it is
conceptually clean, yet fundamental intelligence arises from a being embodied
in an environment whose survival requires daily feedback and decisions on what
actions to take.</p>

<p>Therefore, the next stage is to study realistic open systems that interact with
their environments. The potential complexity of the system and complexity of
the environment should be sufficiently large, such that a level that we denote
as intelligence in daily sense could be reached. This area of study is roughly
known as <em>Embodied Intelligence</em>.</p>

<p>There are two fitting pilot problems to study this area, for example. First,
the current breakthrough of large language model (LLM) is such an
uncertainty-reducing system in a semantic word worlds; the system is trained by
minimizing perplexity, another word for uncertainty. For LLM, the environment
is the Internet, and thus LLM agents are systems that interact with the
environment in the sense of embodied intelligence.  Second, the next
industrial-revolution scale innovation probably comes from cybernetic/control
systems such as self-driving cars, and those are classic embodied systems.
Those two problems are major challenges to realize the transformational impact
of artificial intelligence on societies.</p>

<p>These aforementioned problems also overlap with the area of
alignment.  The developmental progress of an organism is a process where it
explores possible actions in the environment, and accumulates a repository of
<em>action sequences</em> such that it could be more fit to perpetuate in the
environment. Therefore, to align a model is to align this developmental
progress.  Instead of the common denotation of “aligning” catastrophic
superintelligence, alignment might be more like finding the right formalism of
interaction between the environment (e.g., Internet) and the model/agent.</p>

<h2 id="research-problems">Research Problems</h2>

<p>More concretely, some concrete angles that we are working on are
shortly introduced in the following.</p>

<h3 id="foundation-models-for-control">Foundation models for control</h3>

<p>To move beyond the word world, an intelligence in the physical world (e.g.,
autonomous robots) needs somehow to have a mechanism to build abstractions from
raw signals. Natural words are already coarse-grained (in other words,
semantic) information packet of the words, and thus predicting next-word
sidesteps the problem of building coarse-grained abstraction of the
world from raw signals (e.g., pixels). A foundation model for control
needs such abstraction capability, and this abstraction might manifest
as animal-level instinct to navigate in the physical world.</p>

<h3 id="complex-reasoning">Complex reasoning</h3>

<p>In addition to the animal-level instinct, a useful model needs to have
some cognitive ability, manifesting as long-range decision or
reasoning capability. We study this problem under the setting of LLM.
More specifically, next-word prediction might be understood as
something that might be called instincts, and it lacks long-range decision
capability to be useful as an competent assistant (e.g., JARVIS in the film
Iron Man). To make a language model “understand” our request, a
mechanism of feedback and long-chain reasoning need to be
incorporated. Currently, this ability is nascent in language model,
and we are studying how to enable complex and long-range reasoning and
decision in LLM.</p>

<h3 id="superalignment-and-reinforcement-learning-fundamental">Superalignment, and reinforcement learning fundamental</h3>

<p>The previous problems focuses more on the model side of the formalism
(between environment and model/agent), and at the environment side, we
also work on giving language feedback or (AI feedback) for
alignment. The idea is that generation is a NP problem, while
discrimination is a P problem, and thus a good enough model
could self-critique and self-improve. In addition to enabling scalable
alignment, this might provide solution to hard RL problems such as
sparse reward, and instability in RL training.</p>

</div>

    </section>

    

    <nav class="navbar navbar-default navbar-fixed-bottom">
<div class="container footer-content">
    <!-- Nothing is there. -->
</div>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>
</nav>

  </body>

</html>
